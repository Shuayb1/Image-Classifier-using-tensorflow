{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_sets(train_path, validation_size):\n",
    "    IMAGE_FILE_PATH = train_path\n",
    "    filenames = [ os.path.join( IMAGE_FILE_PATH, filename ) for filename in os.listdir( IMAGE_FILE_PATH ) ]\n",
    "    filename_queue = tf.train.string_input_producer( filenames )\n",
    "\n",
    "    image_reader = tf.WholeFileReader()\n",
    "    \n",
    "    _, image_file = image_reader.read(filename_queue)\n",
    "    \n",
    "    image = tf.image.decode_jpeg(image_file)\n",
    "    \n",
    "    image_orig = tf.image.decode_jpeg(image_file)\n",
    "    image = tf.image.resize_images(image_orig, [224, 224])\n",
    "    image.set_shape((224, 224, 3))\n",
    "    batch_size = 50\n",
    "    num_preprocess_threads = 1\n",
    "    min_queue_examples = 256\n",
    "    # min_queue_examples = 600\n",
    "    images = tf.train.shuffle_batch(\n",
    "    [image],\n",
    "    batch_size=batch_size,\n",
    "    num_threads=num_preprocess_threads,\n",
    "    capacity=min_queue_examples + 3 * batch_size,\n",
    "    min_after_dequeue=min_queue_examples)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # Required to get the filename matching to run.\n",
    "        tf.global_variables_initializer().run()    # Coordinate the loading of image files.\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "        # Get an image tensor and print its value.\n",
    "        image_tensor = sess.run(image)\n",
    "        print(image_tensor)\n",
    "\n",
    "        # Finish off the filename queue coordinator.\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Shape mismatch in tuple component 0. Expected [224,224,3], got [224,224,1]\n",
      "\t [[Node: shuffle_batch_1/random_shuffle_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](shuffle_batch_1/random_shuffle_queue, resize_images_1/Squeeze)]]\n",
      "[[[255.       255.       255.      ]\n",
      "  [250.60715  250.60715  250.60715 ]\n",
      "  [232.2857   232.2857   232.2857  ]\n",
      "  ...\n",
      "  [ 79.23216   79.23216   79.23216 ]\n",
      "  [ 84.214325  84.214325  84.214325]\n",
      "  [ 87.        87.        87.      ]]\n",
      "\n",
      " [[254.27232  254.27232  254.27232 ]\n",
      "  [252.54329  252.54329  252.54329 ]\n",
      "  [236.54782  236.54782  236.54782 ]\n",
      "  ...\n",
      "  [ 74.28135   74.28135   74.28135 ]\n",
      "  [ 79.120575  79.120575  79.120575]\n",
      "  [ 81.90625   81.90625   81.90625 ]]\n",
      "\n",
      " [[248.53572  248.53572  248.53572 ]\n",
      "  [252.47098  252.47098  252.47098 ]\n",
      "  [241.16772  241.16772  241.16772 ]\n",
      "  ...\n",
      "  [ 68.419815  68.419815  68.419815]\n",
      "  [ 72.62822   72.62822   72.62822 ]\n",
      "  [ 74.99107   74.99107   74.99107 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 19.81697   19.81697   19.81697 ]\n",
      "  [ 18.352686  18.352686  18.352686]\n",
      "  [ 16.8884    16.8884    16.8884  ]\n",
      "  ...\n",
      "  [ 14.995216  14.995216  14.995216]\n",
      "  [ 23.881279  23.881279  23.881279]\n",
      "  [ 29.798721  29.798721  29.798721]]\n",
      "\n",
      " [[ 20.544647  20.544647  20.544647]\n",
      "  [ 19.080362  19.080362  19.080362]\n",
      "  [ 17.616076  17.616076  17.616076]\n",
      "  ...\n",
      "  [  8.033484   8.033484   8.033484]\n",
      "  [ 10.058346  10.058346  10.058346]\n",
      "  [ 11.919586  11.919586  11.919586]]\n",
      "\n",
      " [[ 21.        21.        21.      ]\n",
      "  [ 19.535715  19.535715  19.535715]\n",
      "  [ 18.071428  18.071428  18.071428]\n",
      "  ...\n",
      "  [  8.374985   8.374985   8.374985]\n",
      "  [  6.464279   6.464279   6.464279]\n",
      "  [  6.         6.         6.      ]]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Shape mismatch in tuple component 0. Expected [224,224,3], got [224,224,1]\n\t [[Node: shuffle_batch_1/random_shuffle_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](shuffle_batch_1/random_shuffle_queue, resize_images_1/Squeeze)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0b13c4a90207>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mread_train_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/home/shuayb/wiki_crop/00'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-164e58ae8eea>\u001b[0m in \u001b[0;36mread_train_sets\u001b[0;34m(train_path, validation_size)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Finish off the filename queue coordinator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[1;32m    387\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mstragglers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_live_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, sess, enqueue_op, coord)\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m           \u001b[0menqueue_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue_closed_exception_types\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=catching-non-exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m           \u001b[0;31m# This exception indicates that a queue was closed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_single_operation_run\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0m_single_operation_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1244\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_tf_sessionrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_single_operation_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape mismatch in tuple component 0. Expected [224,224,3], got [224,224,1]\n\t [[Node: shuffle_batch_1/random_shuffle_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](shuffle_batch_1/random_shuffle_queue, resize_images_1/Squeeze)]]"
     ]
    }
   ],
   "source": [
    "read_train_sets(train_path='/home/shuayb/wiki_crop/00', validation_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filename_queue = tf.train.string_input_producer(\n",
    "# # tf.train.match_filenames_once(\"/home/shuayb/wiki_crop/00\"))\n",
    "\n",
    "# IMAGE_FILE_PATH = '/home/shuayb/wiki_crop/00'\n",
    "# filenames = [ os.path.join( IMAGE_FILE_PATH, filename ) for filename in os.listdir( IMAGE_FILE_PATH ) ]\n",
    "# filename_queue = tf.train.string_input_producer( filenames )\n",
    "\n",
    "# filename_queue = tf.train.string_input_producer(['/home/shuayb/wiki_crop/00/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_reader = tf.WholeFileReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, image_file = image_reader.read(filename_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = tf.image.decode_jpeg(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_orig = tf.image.decode_jpeg(image_file)\n",
    "# image = tf.image.resize_images(image_orig, [224, 224])\n",
    "# image.set_shape((224, 224, 3))\n",
    "# batch_size = 50\n",
    "# num_preprocess_threads = 1\n",
    "# min_queue_examples = 256\n",
    "# # min_queue_examples = 600\n",
    "# images = tf.train.shuffle_batch(\n",
    "# [image],\n",
    "# batch_size=batch_size,\n",
    "# num_threads=num_preprocess_threads,\n",
    "# capacity=min_queue_examples + 3 * batch_size,\n",
    "# min_after_dequeue=min_queue_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with tf.Session() as sess:\n",
    "#     # Required to get the filename matching to run.\n",
    "#     tf.global_variables_initializer().run()    # Coordinate the loading of image files.\n",
    "#     coord = tf.train.Coordinator()\n",
    "#     threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "#     # Get an image tensor and print its value.\n",
    "#     image_tensor = sess.run(image)\n",
    "#     print(image_tensor)\n",
    "\n",
    "#     # Finish off the filename queue coordinator.\n",
    "#     coord.request_stop()\n",
    "#     coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([600, 224, 224,   3], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.truncated_normal([600,224,224,3])\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.shape(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   600, 150528], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=tf.reshape(a,[600,150528])\n",
    "sess.run(tf.shape(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[18.          4.          1.        ]\n",
      "  [18.          4.          1.        ]\n",
      "  [18.          4.          1.        ]\n",
      "  ...\n",
      "  [ 0.          0.          0.        ]\n",
      "  [ 0.          0.          0.        ]\n",
      "  [ 0.          0.          0.        ]]\n",
      "\n",
      " [[15.044643    2.4776785   0.        ]\n",
      "  [15.044643    2.4776785   0.        ]\n",
      "  [15.044643    2.4776785   0.        ]\n",
      "  ...\n",
      "  [ 0.          0.          0.        ]\n",
      "  [ 0.          0.          0.        ]\n",
      "  [ 0.          0.          0.        ]]\n",
      "\n",
      " [[14.955357    3.955357    0.        ]\n",
      "  [14.955357    3.955357    0.        ]\n",
      "  [14.955357    3.955357    0.        ]\n",
      "  ...\n",
      "  [ 0.          0.          0.        ]\n",
      "  [ 0.          0.          0.        ]\n",
      "  [ 0.          0.          0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.          0.          0.        ]\n",
      "  [ 0.          0.          0.        ]\n",
      "  [ 0.          0.          0.        ]\n",
      "  ...\n",
      "  [ 2.          2.6249452   0.        ]\n",
      "  [ 0.84675467  1.8660889   0.        ]\n",
      "  [ 0.43304443  1.8660889   0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.        ]\n",
      "  [ 0.          0.          0.        ]\n",
      "  [ 0.          0.          0.        ]\n",
      "  ...\n",
      "  [ 3.974687    4.9360185   0.        ]\n",
      "  [ 0.04265384  1.9573462   0.        ]\n",
      "  [ 0.          2.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.        ]\n",
      "  [ 0.          0.          0.        ]\n",
      "  [ 0.          0.          0.        ]\n",
      "  ...\n",
      "  [ 3.2068617   2.7485216   0.        ]\n",
      "  [ 1.4776611   1.0213276   0.        ]\n",
      "  [ 0.52230835  1.4776917   0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "classes = ['male', 'female']\n",
    "num_classes = len(classes)\n",
    " \n",
    "train_path ='/home/shuayb/wiki_crop/00'\n",
    " \n",
    "# validation split\n",
    "validation_size = 0.2\n",
    " \n",
    "# batch size\n",
    "batch_size = 600\n",
    " \n",
    "data = read_train_sets(train_path, validation_size=validation_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    " \n",
    "def create_biases(size):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://cv-tricks.com/tensorflow-tutorial/training-convolutional-neural-network-for-image-classification/\n",
    "# https://gist.github.com/eerwitt/518b0c9564e500b4b50f\n",
    "# https://www.datacamp.com/community/tutorials/tensorflow-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
